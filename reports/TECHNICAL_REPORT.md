# Enhanced Vehicle Efficiency Analysis — Technical Report

This document explains the complete analysis workflow, data, modeling choices, fine-tuning strategy, evaluation metrics, outputs, and how to reproduce results. See also `reports/final_modeling_report.docx` for a Word version with embedded figures.

## 1. Introduction

Goal: Predict vehicle efficiency for EV and ICE cohorts and compare model performance across multiple algorithms with feature engineering, robust validation, and targeted fine-tuning.

## 2. Data

- Source: `data/vehicle_comparison_dataset_030417.csv`
- Target: `efficiency = mileage_km / energy_consumption` (computed at load time)
- Outliers: Removed by IQR filtering on `efficiency`
- Cohorts: Split on `vehicle_type` (EV vs ICE); `vehicle_type` dropped from features
- Safety cleanups: Negative `co2_emissions_g_per_km` clipped to 0

## 3. Feature Engineering

Engineered domain features include ratios, environmental metrics, categorical bins converted to codes, polynomial and interaction terms, log transforms, and normalized features. Data leakage is prevented by removing `mileage_km` and `energy_consumption` from modeling features.

## 4. Feature Selection

- Filter by correlation with target (EV>0.02; ICE>0.03)
- Remove near-zero variance features
- Greedy multicollinearity pruning (|corr| < 0.85)
- Cap at 20 features

## 5. Modeling

- Algorithms: Linear, Ridge, Lasso, Decision Tree, Random Forest, Gradient Boosting; optional XGBoost, LightGBM, CatBoost
- Preprocessing: PowerTransformer for linear models; raw features for tree/boosting
- Validation: 5-fold KFold (shuffle, random_state=42), scoring via MAE
- Hold-out metrics: MAE, RMSE, R²
- Ranking: Sort by `test_r2` (default) or `test_mae`

## 6. Fine-Tuning

Top 2 models per cohort are tuned:
- Boosting: Optuna (trials configurable); fallback to sklearn search
- Non-boosting: RandomizedSearchCV (default) or GridSearchCV
- Tuning metric: MAE (default) or R²
- Report includes Tuned vs Base deltas when a tuned model is best

## 7. Outputs

- Rankings: `output/enhanced_ev_model_rankings.csv`, `output/enhanced_ice_model_rankings.csv`
- Best models: `output/best_enhanced_ev_model.joblib`, `output/best_enhanced_ice_model.joblib`
- Parameters: `output/ev_model_parameters.json`, `output/ice_model_parameters.json`
- Selected features: `output/ev_selected_features.json`, `output/ice_selected_features.json`
- Results summary: `output/enhanced_analysis_results.json`
- Final report (Markdown): `output/final_modeling_report.md`
- Word report: `reports/final_modeling_report.docx` (generated by script)
- Visualizations:
  - Main: `output/enhanced_efficiency_dashboard.png`
  - CV Stability: `output/cv_stability_{ev,ice,comparison}.png`
  - Advanced: `output/individual_plots/01..15_*.png`, `output/correlation_analysis_dashboard.png`, `output/detailed_correlation_matrices.png`
- Logs: `output/logs/pipeline.log`

## 8. How to Run

Install deps:

```bash
pip install -r requirements.txt
```

Run full pipeline (defaults: full viz + fine-tuning enabled):

```bash
python scripts/run_enhanced.py --data-path data/vehicle_comparison_dataset_030417.csv --output-dir output
```

Back-compat wrapper:

```bash
python enhanced_vehicle_efficiency_analysis.py --data-path data/vehicle_comparison_dataset_030417.csv --output-dir output
```

Generate Word report (ensure `python-docx` installed):

```bash
pip install python-docx
python scripts/generate_word_report.py
```

## 9. Reproducibility & Logging

- Random seeds fixed where applicable (`random_state=42`)
- Cross-validation with fixed splits
- Loguru logs to console and `output/logs/pipeline.log`

## 10. Notes & Limitations

- R² may be near-zero/negative for some cohorts; MAE often more interpretable
- PowerTransformer aids linear models; trees are scale-invariant
- Optuna usage is optional; falls back to sklearn searches

